{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Notebook 3 – Natural Language Classifier (NLC)\n",
    "IBM Watson Natural Language Classifier uses machine learning algorithms to return the top matching predefined classes for short text input. \n",
    "\n",
    "*YOU* Create and train a classifier to connect predefined classes to example texts so that the service can apply those classes to new inputs.\n",
    "\n",
    "https://www.ibm.com/watson/services/natural-language-classifier/ \n",
    "https://www.ibm.com/watson/developercloud/natural-language-classifier/api/v1 \n",
    "\n",
    "\n",
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports.... Run this each time after restarting the Kernel\n",
    "#!pip install watson_developer_cloud\n",
    "import watson_developer_cloud as watson\n",
    "import json\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cloud Object Storage - Add Credentials & Bucket Name\n",
    "If you've not already set up COS - please see Step 1\n",
    "\n",
    "### Credentials\n",
    "Credentials are also created for you when you create project. From service dashboard page select `Service Credentials` from left navigation menu item, and copy/paste the credentials below:\n",
    "\n",
    "### Bucket name\n",
    "Buckets are created for you when you create project. From service dashboard page select `Buckets` from left navigation menu item, and get your bucket name and copy/paste bucket name below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Cloud Object Storage - populate your own information here from \"SERVICES\" on this page, or Console Dashboard on ibm.com/cloud\n",
    "\n",
    "# From service dashboard page select Service Credentials from left navigation menu item\n",
    "credentials_os = {\n",
    "  \"apikey\": \"\",\n",
    "  \"cos_hmac_keys\": {\n",
    "    \"access_key_id\": \"\",\n",
    "    \"secret_access_key\": \"\"\n",
    "  },\n",
    "  \"endpoints\": \"https://cos-service.bluemix.net/endpoints\",\n",
    "  \"iam_apikey_description\": \"Auto generated apikey during resource-key operation for Instance\",\n",
    "  \"iam_apikey_name\": \"\",\n",
    "  \"iam_role_crn\": \"\",\n",
    "  \"iam_serviceid_crn\": \"\",\n",
    "  \"resource_instance_id\": \"\"\n",
    "}\n",
    "\n",
    "# Buckets are created for you when you create project. From service dashboard page select Buckets from left navigation menu item, \n",
    "credentials_os['BUCKET'] = '<bucket_name>' # copy bucket name from COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code was removed by DSX for sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACCESS (pre-trained) Watson Natural Language Classifier (NLC) service for lab\n",
    "### (*) NLC does NOT OFFER LITE PLAN and NLC also takes time to train\n",
    "\n",
    "For this lab - to keep things simple - NLC has been PRE CONFIGURED for you. \n",
    "\n",
    "IBM Watson™ Natural Language Classifier uses machine learning algorithms to return the top matching predefined classes for short text input. You create and train a classifier to connect predefined classes to example texts so that the service can apply those classes to new inputs.\n",
    "\n",
    "In short - YOU can train the NLC with a ground truth - to create your own classification model\n",
    "\n",
    "https://www.ibm.com/watson/developercloud/natural-language-classifier/api/v1/curl.html?curl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAB CREDENTIALS FOR YOU - Credentials will only be available till March 23, 2018; afterward you need to train your own classifier\n",
    "\n",
    "credentials_nlc = {\n",
    "    \"classifier_id\": \"f7ea68x308-nlc-917\",\n",
    "    \"url\": \"https://gateway.watsonplatform.net/natural-language-classifier/api\",\n",
    "    \"apikey\": \"280b9633-d8c0-4ed2-9ee6-1b2c139516fb\",\n",
    "}\n",
    "# Ground truth used - simple tester \"call_center_gt_NLC_V2.csv\"\n",
    "# https://github.com/rustyoldrake/call_center_instrumentation_analytics/blob/master/call_center_gt_NLC_V2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Object Storage Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = requests.get(credentials_os['endpoints']).json()\n",
    "\n",
    "iam_host = (endpoints['identity-endpoints']['iam-token'])\n",
    "cos_host = (endpoints['service-endpoints']['cross-region']['us']['public']['us-geo'])\n",
    "\n",
    "auth_endpoint = \"https://\" + iam_host + \"/oidc/token\"\n",
    "service_endpoint = \"https://\" + cos_host\n",
    "\n",
    "\n",
    "client = ibm_boto3.client(\n",
    "    's3',\n",
    "    ibm_api_key_id = credentials_os['apikey'],\n",
    "    ibm_service_instance_id = credentials_os['resource_instance_id'],\n",
    "    ibm_auth_endpoint = auth_endpoint,\n",
    "    config = Config(signature_version='oauth'),\n",
    "    endpoint_url = service_endpoint\n",
    "   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLC\n",
    "\n",
    "- `process_text()` goes throught the text and fetch sentences and concatenate transcript based on chunk size\n",
    "- `classify()` calls natural language classifier endpoint and classify the text fields in transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLC\n",
    "\n",
    "from watson_developer_cloud import NaturalLanguageClassifierV1\n",
    "\n",
    "natural_language_classifier = NaturalLanguageClassifierV1(\n",
    "    iam_apikey='{iam_api_key}', = credentials_nlc['apikey'])\n",
    "\n",
    "chunk_size = 25\n",
    "# Used to SPLIT up - \"CHUNK\" the aggregate transcript into smaller pieces\n",
    "\n",
    "def chunk_transcript(transcript, chunk_size):\n",
    "    transcript = transcript.split(' ')\n",
    "    return [ transcript[i:i+chunk_size] for i in range(0, len(transcript), chunk_size) ] # chunking data\n",
    "    \n",
    "\n",
    "def process_text(text):\n",
    "    transcript=''\n",
    "    for sentence in json.loads(text)['results']:\n",
    "        transcript = transcript + sentence['alternatives'][0]['transcript'] # concatenate sentences\n",
    "    transcript = chunk_transcript(transcript, chunk_size) # chunk the transcript\n",
    "    return transcript\n",
    "\n",
    "def classify(file_name):\n",
    "    streaming_body = client.get_object(Bucket = credentials_os['BUCKET'], Key = file_name.split('.')[0]+'_text.json')['Body']\n",
    "    transcript=streaming_body.read().decode(\"utf-8\")\n",
    "    analysis = {}\n",
    "    for chunk in process_text(transcript):\n",
    "        chunk = ' '.join(chunk)\n",
    "        analysis[chunk] = natural_language_classifier.classify(credentials_nlc['classifier_id'], chunk).get_result()\n",
    "    client.put_object(Bucket = credentials_os['BUCKET'], Key = file_name.split('.')[0]+'_nlc', Body= json.dumps(analysis))\n",
    "    return analysis\n",
    "\n",
    "\n",
    "def classify_transcript(file_name):\n",
    "    status = natural_language_classifier.get_classifier(credentials_nlc['classifier_id'])\n",
    "    if status['status'] == 'Available':\n",
    "        classes = classify(file_name)\n",
    "    return classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "WatsonApiException",
     "evalue": "Error: Unauthorized: Access is denied due to invalid credentials , Code: 401 , X-dp-watson-tran-id: gateway02-3942423309 , X-global-transaction-id: ffea405d5c0302b5eafc9b0d",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWatsonApiException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3a9ade62a336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mclassify_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-4fa6100581c0>\u001b[0m in \u001b[0;36mclassify_transcript\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclassify_transcript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnatural_language_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials_nlc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Available'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/watson_developer_cloud/natural_language_classifier_v1.py\u001b[0m in \u001b[0;36mget_classifier\u001b[0;34m(self, classifier_id, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m             *self._encode_path_vars(classifier_id))\n\u001b[1;32m    272\u001b[0m         response = self.request(\n\u001b[0;32m--> 273\u001b[0;31m             method='GET', url=url, headers=headers, accept_json=True)\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/watson_developer_cloud/watson_service.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, accept_json, headers, params, json, data, files, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0merror_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_error_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             raise WatsonApiException(response.status_code, error_message,\n\u001b[0;32m--> 495\u001b[0;31m                                      info=error_info, httpResponse=response)\n\u001b[0m",
      "\u001b[0;31mWatsonApiException\u001b[0m: Error: Unauthorized: Access is denied due to invalid credentials , Code: 401 , X-dp-watson-tran-id: gateway02-3942423309 , X-global-transaction-id: ffea405d5c0302b5eafc9b0d"
     ]
    }
   ],
   "source": [
    "file_list = ['sample1-addresschange-positive.ogg',\n",
    "             'sample2-address-negative.ogg',\n",
    "             'sample3-shirt-return-weather-chitchat.ogg',\n",
    "             'sample4-angryblender-sportschitchat-recovery.ogg',\n",
    "             'sample5-calibration-toneandcontext.ogg',\n",
    "             'jfk_1961_0525_speech_to_put_man_on_moon.ogg',\n",
    "             'May 1 1969 Fred Rogers testifies before the Senate Subcommittee on Communications.ogg'\n",
    "            ]\n",
    "\n",
    "\n",
    "classify_transcript(file_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in file_list:\n",
    "    print(\"\\n\\nprocessing file: \", filename)\n",
    "    analysis = classify_transcript(filename)\n",
    "    print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
